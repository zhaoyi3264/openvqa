{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqAZLp3XRavH"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ASZDou59uiE",
    "outputId": "78892463-b975-4ec8-d003-d2ef7662da34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50RpFIK5Qqjb"
   },
   "source": [
    "## Test set features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "78Ab9xtK9gP8"
   },
   "outputs": [],
   "source": [
    "!tar xzf /content/drive/MyDrive/stat453/test2015.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAsqCUkoGu6P",
    "outputId": "b39da40a-89d1-4b2a-833d-99fd9e479e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81434\n"
     ]
    }
   ],
   "source": [
    "!ls data/vqa/feats/test2015/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLQzXtJ_BTMd"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/zhaoyi3264/openvqa.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DJ042yxlB_Hd"
   },
   "outputs": [],
   "source": [
    "!mv test2015/ openvqa/data/vqa/feats/\n",
    "!mkdir openvqa/data/vqa/feats/train2014\n",
    "!mkdir openvqa/data/vqa/feats/val2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqUEFkauQ1j3"
   },
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "quiQmrNNCaFV"
   },
   "outputs": [],
   "source": [
    "!mv *.json openvqa/data/vqa/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka4xSDWxQ6dD"
   },
   "source": [
    "## Pre-trained model (BAN-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYGUByO8Fle0"
   },
   "outputs": [],
   "source": [
    "!wget https://awma1-my.sharepoint.com/:u:/g/personal/yuz_l0_tn/EbJgyL7FPTFAqzMm3HB1xDIBjXpWygOoXrdnDZKEIu34rg?download=1 -O epoch13.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Fx_wtxreF5rT"
   },
   "outputs": [],
   "source": [
    "!mkdir openvqa/ckpts/ckpt_ban_8/\n",
    "!mv ban_8.pkl openvqa/ckpts/ckpt_ban_8/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBdkG8PTRAp4"
   },
   "source": [
    "## Spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9IreGohFF6H"
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/explosion/spacy-models/releases/download/en_vectors_web_lg-2.1.0/en_vectors_web_lg-2.1.0.tar.gz -O en_vectors_web_lg-2.1.0.tar.gz\n",
    "# !pip install -q en_vectors_web_lg-2.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CToSkXelIhro"
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDHHBqnjRij2"
   },
   "source": [
    "## Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFBMHegVYwgx"
   },
   "source": [
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/openvqa/core/base_cfgs.py\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/utils/exec.py#L36\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/utils/test_engine.py#L49\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/openvqa/datasets/vqa/vqa_loader.py#L68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyONyychRXaF"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DobaMYxcDkgN",
    "outputId": "712710aa-4b87-4116-da83-4c29a5ab6c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/openvqa\n"
     ]
    }
   ],
   "source": [
    "%cd /content/openvqa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08lNunGuD52d",
    "outputId": "f7a39a95-7e65-477d-97d8-8048a7b50c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset ........\n",
      "Finished!\n",
      "\n",
      "Hyper Parameters:\n",
      "{ BATCH_SIZE        }->512\n",
      "{ BA_HIDDEN_SIZE    }->3072\n",
      "{ BBOX_NORMALIZE    }->False\n",
      "{ CACHE_PATH        }->./results/cache\n",
      "{ CKPTS_PATH        }->./ckpts\n",
      "{ CKPT_EPOCH        }->13\n",
      "{ CKPT_PATH         }->None\n",
      "{ CKPT_VERSION      }->ban_8\n",
      "{ CLASSIFER_DROPOUT_R }->0.5\n",
      "{ DATASET           }->vqa\n",
      "{ DATA_PATH         }->{'vqa': './data/vqa', 'gqa': './data/gqa', 'clevr': './data/clevr'}\n",
      "{ DATA_ROOT         }->./data\n",
      "{ DEVICES           }->[0]\n",
      "{ DROPOUT_R         }->0.2\n",
      "{ EVAL_BATCH_SIZE   }->32\n",
      "{ EVAL_EVERY_EPOCH  }->False\n",
      "{ FEATS_PATH        }->{'vqa': {'train': './data/vqa/feats/train2014', 'val': './data/vqa/feats/val2014', 'test': './data/vqa/feats/test2015'}, 'gqa': {'default-frcn': './data/gqa/feats/gqa-frcn', 'default-grid': './data/gqa/feats/gqa-grid'}, 'clevr': {'train': './data/clevr/feats/train', 'val': './data/clevr/feats/val', 'test': './data/clevr/feats/test'}}\n",
      "{ FEAT_SIZE         }->{'vqa': {'FRCN_FEAT_SIZE': (100, 2048), 'BBOX_FEAT_SIZE': (100, 5)}, 'gqa': {'FRCN_FEAT_SIZE': (100, 2048), 'GRID_FEAT_SIZE': (49, 2048), 'BBOX_FEAT_SIZE': (100, 5)}, 'clevr': {'GRID_FEAT_SIZE': (196, 1024)}}\n",
      "{ FLAT_OUT_SIZE     }->2048\n",
      "{ GLIMPSE           }->8\n",
      "{ GPU               }->0\n",
      "{ GRAD_ACCU_STEPS   }->8\n",
      "{ GRAD_NORM_CLIP    }->0.25\n",
      "{ HIDDEN_SIZE       }->1024\n",
      "{ IMG_FEAT_SIZE     }->2048\n",
      "{ K_TIMES           }->3\n",
      "{ LOG_PATH          }->./results/log\n",
      "{ LOSS_FUNC         }->bce\n",
      "{ LOSS_FUNC_NAME_DICT }->{'ce': 'CrossEntropyLoss', 'bce': 'BCEWithLogitsLoss', 'kld': 'KLDivLoss', 'mse': 'MSELoss'}\n",
      "{ LOSS_FUNC_NONLINEAR }->{'ce': [None, 'flat'], 'bce': [None, None], 'kld': ['log_softmax', None], 'mse': [None, None]}\n",
      "{ LOSS_REDUCTION    }->sum\n",
      "{ LR_BASE           }->0.002\n",
      "{ LR_DECAY_LIST     }->[10, 12]\n",
      "{ LR_DECAY_R        }->0.25\n",
      "{ MAX_EPOCH         }->13\n",
      "{ MODEL             }->ban_8\n",
      "{ MODEL_USE         }->ban\n",
      "{ NUM_WORKERS       }->2\n",
      "{ N_GPU             }->1\n",
      "{ OPT               }->Adamax\n",
      "{ OPT_PARAMS        }->{'betas': (0.9, 0.999), 'eps': 1e-09, 'weight_decay': 0}\n",
      "{ PIN_MEM           }->True\n",
      "{ PRED_PATH         }->./results/pred\n",
      "{ RAW_PATH          }->{'vqa': {'train': './data/vqa/raw/v2_OpenEnded_mscoco_train2014_questions.json', 'train-anno': './data/vqa/raw/v2_mscoco_train2014_annotations.json', 'val': './data/vqa/raw/v2_OpenEnded_mscoco_val2014_questions.json', 'val-anno': './data/vqa/raw/v2_mscoco_val2014_annotations.json', 'vg': './data/vqa/raw/VG_questions.json', 'vg-anno': './data/vqa/raw/VG_annotations.json', 'test': './data/vqa/raw/v2_OpenEnded_mscoco_test2015_questions.json'}, 'gqa': {'train': './data/gqa/raw/questions1.2/train_balanced_questions.json', 'val': './data/gqa/raw/questions1.2/val_balanced_questions.json', 'testdev': './data/gqa/raw/questions1.2/testdev_balanced_questions.json', 'test': './data/gqa/raw/questions1.2/submission_all_questions.json', 'val_all': './data/gqa/raw/questions1.2/val_all_questions.json', 'testdev_all': './data/gqa/raw/questions1.2/testdev_all_questions.json', 'train_choices': './data/gqa/raw/eval/train_choices', 'val_choices': './data/gqa/raw/eval/val_choices.json'}, 'clevr': {'train': './data/clevr/raw/questions/CLEVR_train_questions.json', 'val': './data/clevr/raw/questions/CLEVR_val_questions.json', 'test': './data/clevr/raw/questions/CLEVR_test_questions.json'}}\n",
      "{ RESULT_PATH       }->./results/result_test\n",
      "{ RESUME            }->False\n",
      "{ RUN_MODE          }->test\n",
      "{ SEED              }->385647\n",
      "{ SPLIT             }->{'train': 'train', 'val': 'val', 'test': 'test'}\n",
      "{ SPLITS            }->{'vqa': {'train': 'train', 'val': 'val', 'test': 'test'}, 'gqa': {'train': '', 'val': 'testdev', 'test': 'test'}, 'clevr': {'train': '', 'val': 'val', 'test': 'test'}}\n",
      "{ SUB_BATCH_SIZE    }->64\n",
      "{ TASK_LOSS_CHECK   }->{'vqa': ['bce', 'kld'], 'gqa': ['ce'], 'clevr': ['ce']}\n",
      "{ TEST_SAVE_PRED    }->False\n",
      "{ TRAIN_SPLIT       }->train\n",
      "{ USE_GLOVE         }->True\n",
      "{ VERBOSE           }->True\n",
      "{ VERSION           }->385647\n",
      "{ WARMUP_EPOCH      }->3\n",
      "{ WORD_EMBED_SIZE   }->300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import yaml\n",
    "from yaml import CLoader\n",
    "\n",
    "from openvqa.datasets.dataset_loader import DatasetLoader, EvalLoader\n",
    "from openvqa.datasets.vqa.eval.vqa import VQA\n",
    "from openvqa.datasets.vqa.eval.vqaEval import VQAEval\n",
    "from openvqa.models.model_loader import CfgLoader, ModelLoader\n",
    "from run import create_parser\n",
    "from utils.test_engine import test_engine\n",
    "\n",
    "parser = create_parser()\n",
    "arg = '--RUN test --MODEL ban_8 --DATASET vqa --NW 2 --CKPT_V ban_8 --CKPT_E 13'\n",
    "args = parser.parse_args(arg.split(' '))\n",
    "\n",
    "cfg_file = \"configs/{}/{}.yml\".format(args.DATASET, args.MODEL)\n",
    "with open(cfg_file, 'r') as f:\n",
    "    yaml_dict = yaml.load(f, Loader=CLoader)\n",
    "\n",
    "__C = CfgLoader(yaml_dict['MODEL_USE']).load()\n",
    "args = __C.str_to_bool(args)\n",
    "args_dict = __C.parse_to_dict(args)\n",
    "\n",
    "args_dict = {**yaml_dict, **args_dict}\n",
    "__C.add_args(args_dict)\n",
    "__C.proc()\n",
    "\n",
    "print('Hyper Parameters:')\n",
    "print(__C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czhtig1Y8zZO",
    "outputId": "7e96770a-4c0a-4e32-f467-6f12a9bc6321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== Dataset size: 447793\n",
      " ========== Question token vocab size: 20573\n",
      " ========== Answer token vocab size (occur more than 8 times): 3129\n",
      "Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetLoader(__C).DataSet()\n",
    "\n",
    "data_size = dataset.data_size\n",
    "token_size = dataset.token_size\n",
    "ans_size = dataset.ans_size\n",
    "pretrained_emb = dataset.pretrained_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s56dZbZK_MJ",
    "outputId": "037027f0-ad9d-4a90-fd0d-26c0ed16535a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ModelLoader(__C).Net(\n",
    "    __C,\n",
    "    pretrained_emb,\n",
    "    token_size,\n",
    "    ans_size\n",
    ")\n",
    "\n",
    "# net.cuda()\n",
    "net.eval()\n",
    "\n",
    "with open('ckpts/ckpt_ban_8/epoch13.pkl', 'rb') as f:\n",
    "    state = torch.load(f, map_location='cpu')\n",
    "net.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Agvd5qHvWSo1"
   },
   "outputs": [],
   "source": [
    "dataloader = Data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=__C.EVAL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=__C.NUM_WORKERS,\n",
    "    pin_memory=__C.PIN_MEM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v.shape:\t torch.Size([32, 100, 2048])\n",
      "q.shape:\t torch.Size([32, 14, 1024])\n",
      "att.shape:\t torch.Size([32, 8, 100, 14])\n",
      "v.shape:\t torch.Size([32, 100, 2048])\n",
      "q.shape:\t torch.Size([32, 14, 1024])\n",
      "att.shape:\t torch.Size([32, 8, 100, 14])\n",
      "v.shape:\t torch.Size([32, 100, 2048])\n",
      "q.shape:\t torch.Size([32, 14, 1024])\n",
      "att.shape:\t torch.Size([32, 8, 100, 14])\n",
      "v.shape:\t torch.Size([32, 100, 2048])\n",
      "q.shape:\t torch.Size([32, 14, 1024])\n",
      "att.shape:\t torch.Size([32, 8, 100, 14])\n"
     ]
    }
   ],
   "source": [
    "atts = []\n",
    "i = 0\n",
    "for frcn_feat, grid_feat, bbox_feat, ques_ix, ans in dataloader:\n",
    "    lang_feat = net.embedding(ques_ix)\n",
    "    lang_feat, _ = net.rnn(lang_feat)\n",
    "\n",
    "    img_feat, _ = net.adapter(frcn_feat, grid_feat, bbox_feat)\n",
    "    \n",
    "    v, q = img_feat, lang_feat\n",
    "    print('v.shape:\\t', v.shape)\n",
    "    print('q.shape:\\t', q.shape)\n",
    "    \n",
    "    att, logits = net.backbone.BiAtt(v, q)\n",
    "    print('att.shape:\\t', att.shape)\n",
    "    \n",
    "    atts.append(att.detach().numpy().sum(axis=-1).mean(axis=0))\n",
    "    i += 1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.concatenate(atts)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.937662760416664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.nbytes / 1024 / 1024 * 13993 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = att[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 100, 14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.sum(axis=-1).mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhxB1MggRzVW"
   },
   "source": [
    "# Prediction (on test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpoSdOZgaMr_",
    "outputId": "f06cd941-978d-479c-d532-24ab7680f68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [step 13993/13993]          CPU times: user 13min 48s, sys: 8min 59s, total: 22min 47s\n",
      "Wall time: 35min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans_ix_list = []\n",
    "pred_list = []\n",
    "\n",
    "for step, (\n",
    "        frcn_feat_iter,\n",
    "        grid_feat_iter,\n",
    "        bbox_Predictionfeat_iter,\n",
    "        ques_ix_iter,\n",
    "        ans_iter\n",
    "    ) in enumerate(dataloader):\n",
    "    print(\"\\rEvaluation: [step %4d/%4d]\" % (\n",
    "        step,\n",
    "        int(data_size / __C.EVAL_BATCH_SIZE),\n",
    "    ), end='          ')\n",
    "\n",
    "    frcn_feat_iter = frcn_feat_iter.cuda()\n",
    "    grid_feat_iter = grid_feat_iter.cuda()\n",
    "    bbox_feat_iter = bbox_feat_iter.cuda()\n",
    "    ques_ix_iter = ques_ix_iter.cuda()\n",
    "\n",
    "    pred = net(\n",
    "        frcn_feat_iter,\n",
    "        grid_feat_iter,\n",
    "        bbox_feat_iter,\n",
    "        ques_ix_iter\n",
    "    )\n",
    "\n",
    "    pred_np = pred.cpu().data.numpy()\n",
    "    pred_argmax = np.argmax(pred_np, axis=1)\n",
    "    \n",
    "    if pred_argmax.shape[0] != __C.EVAL_BATCH_SIZE:\n",
    "        pred_argmax = np.pad(\n",
    "            pred_argmax,\n",
    "            (0, __C.EVAL_BATCH_SIZE - pred_argmax.shape[0]),\n",
    "            mode='constant',\n",
    "            constant_values=-1\n",
    "        )\n",
    "\n",
    "    ans_ix_list.append(pred_argmax)\n",
    "    \n",
    "    if __C.TEST_SAVE_PRED:\n",
    "        if pred_np.shape[0] != __C.EVAL_BATCH_SIZE:\n",
    "            pred_np = np.pad(\n",
    "                pred_np,\n",
    "                ((0, __C.EVAL_BATCH_SIZE - pred_np.shape[0]), (0, 0)),\n",
    "                mode='constant',\n",
    "                constant_values=-1\n",
    "            )\n",
    "\n",
    "        pred_list.append(pred_np)\n",
    "\n",
    "# Evaluation: [step 6698/6698]\n",
    "# CPU times: user 14h 57min 55s, sys: 19min 55s, total: 15h 17min 51s\n",
    "# Wall time: 7h 40min 34s\n",
    "# Evaluation: [step 13993/13993]\n",
    "# CPU times: user 13min 48s, sys: 8min 59s, total: 22min 47s\n",
    "# Wall time: 35min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKX9LFIc9cti",
    "outputId": "286e8440-2350-4d5b-fc99-268fcbd04fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the result to file: ./results/cache/result_run_6911998.json\n"
     ]
    }
   ],
   "source": [
    "ans_ix_list = np.array(ans_ix_list).reshape(-1)\n",
    "\n",
    "qid_list = [ques['question_id'] for ques in dataset.ques_list]\n",
    "ans_size = dataset.ans_size\n",
    "\n",
    "result = [{\n",
    "        'answer': dataset.ix_to_ans[str(ans_ix_list[qix])],\n",
    "        'question_id': int(qid_list[qix])\n",
    "    } for qix in range(qid_list.__len__())]\n",
    "\n",
    "result_eval_file = __C.CACHE_PATH + '/result_run_' + __C.VERSION\n",
    "log_file = __C.LOG_PATH + '/log_run_' + __C.VERSION + '.txt'\n",
    "result_eval_file += '.json'\n",
    "print('Save the result to file: {}'.format(result_eval_file))\n",
    "with open(result_eval_file, 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hdcIm1NR4vv"
   },
   "source": [
    "# Evaluation (on validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hM2f7Wa79cti",
    "outputId": "9a6511fe-b6bc-4928-e264-a94438ef7a8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:05.052310\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.46s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "result_eval_file = __C.CACHE_PATH + '/result_run_' + __C.VERSION\n",
    "result_eval_file += '.json'\n",
    "\n",
    "ques_file_path = __C.RAW_PATH[__C.DATASET][__C.SPLIT['val']]\n",
    "ans_file_path = __C.RAW_PATH[__C.DATASET][__C.SPLIT['val'] + '-anno']\n",
    "# uncomment line 165-166 in http://localhost:8888/edit/openvqa/openvqa/datasets/vqa/eval/vqa.py\n",
    "vqa = VQA(ans_file_path, ques_file_path)\n",
    "vqaRes = vqa.loadRes(result_eval_file, ques_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwwh_z9P9ctj",
    "outputId": "dd21cb3e-63ea-4776-a055-27214f6ac96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing accuracy\n",
      "Finished Percent: [####################] 99% Done computing accuracy\n"
     ]
    }
   ],
   "source": [
    "vqaEval = VQAEval(vqa, vqaRes, n=2)\n",
    "\n",
    "# quesIds = [d['question_id'] for d in result]\n",
    "# vqaEval.evaluate(quesIds)\n",
    "vqaEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Yd0wNsg9ctk",
    "outputId": "3e7350c2-cb9b-43c8-c5e7-f2c8b0cb8d11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 84.09,\n",
       " 'perQuestionType': {'none of the above': 82.19,\n",
       "  'what are the': 75.57,\n",
       "  'what is': 75.66,\n",
       "  'what': 69.0,\n",
       "  'is this a': 97.88,\n",
       "  'is this': 97.46,\n",
       "  'what is the man': 84.12,\n",
       "  'how many': 75.92,\n",
       "  'what does the': 48.29,\n",
       "  'why': 46.35,\n",
       "  'is it': 98.84,\n",
       "  'why is the': 47.41,\n",
       "  'what color is the': 92.15,\n",
       "  'is there a': 98.67,\n",
       "  'is the': 96.79,\n",
       "  'is that a': 97.79,\n",
       "  'are these': 96.65,\n",
       "  'are the': 96.26,\n",
       "  'what is the': 75.58,\n",
       "  'which': 68.28,\n",
       "  'could': 98.61,\n",
       "  'are there': 98.21,\n",
       "  'what kind of': 76.9,\n",
       "  'has': 97.16,\n",
       "  'what color are the': 91.07,\n",
       "  'are there any': 99.08,\n",
       "  'is this person': 98.05,\n",
       "  'does the': 97.25,\n",
       "  'where is the': 60.6,\n",
       "  'how many people are': 74.58,\n",
       "  'can you': 97.58,\n",
       "  'what type of': 77.29,\n",
       "  'what is the color of the': 92.4,\n",
       "  'what is on the': 76.11,\n",
       "  'does this': 97.48,\n",
       "  'is this an': 97.49,\n",
       "  'who is': 63.25,\n",
       "  'what is this': 84.76,\n",
       "  'is there': 98.29,\n",
       "  'are': 95.61,\n",
       "  'what time': 45.95,\n",
       "  'how': 54.52,\n",
       "  'what is in the': 82.44,\n",
       "  'do you': 98.56,\n",
       "  'what are': 82.12,\n",
       "  'what sport is': 96.99,\n",
       "  'what is the person': 85.1,\n",
       "  'is he': 97.53,\n",
       "  'where are the': 62.22,\n",
       "  'what brand': 63.21,\n",
       "  'what number is': 31.31,\n",
       "  'what color is': 92.86,\n",
       "  'what is the woman': 81.28,\n",
       "  'what room is': 97.59,\n",
       "  'is': 96.83,\n",
       "  'what color': 88.12,\n",
       "  'is the woman': 96.96,\n",
       "  'are they': 97.53,\n",
       "  'is the person': 97.58,\n",
       "  'is the man': 97.35,\n",
       "  'what animal is': 90.35,\n",
       "  'what is the name': 32.58,\n",
       "  'was': 97.43,\n",
       "  'do': 95.87,\n",
       "  'how many people are in': 78.74},\n",
       " 'perAnswerType': {'other': 77.52, 'yes/no': 97.97, 'number': 69.03}}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqaEval.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIGU9OEt9ctk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "openvqa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
