{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CToSkXelIhro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9IreGohFF6H"
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/explosion/spacy-models/releases/download/en_vectors_web_lg-2.1.0/en_vectors_web_lg-2.1.0.tar.gz -O en_vectors_web_lg-2.1.0.tar.gz\n",
    "# !pip install -q en_vectors_web_lg-2.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFBMHegVYwgx"
   },
   "source": [
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/openvqa/core/base_cfgs.py\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/utils/exec.py#L36\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/utils/test_engine.py#L49\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/openvqa/datasets/vqa/vqa_loader.py#L68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6133"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08lNunGuD52d",
    "outputId": "659e1203-6b94-4f43-c7e5-d0f4c51713b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset ........\n",
      "Finished!\n",
      "\n",
      "Hyper Parameters:\n",
      "{ BATCH_SIZE        }->512\n",
      "{ BA_HIDDEN_SIZE    }->3072\n",
      "{ BBOX_NORMALIZE    }->False\n",
      "{ CACHE_PATH        }->./results/cache\n",
      "{ CKPTS_PATH        }->./ckpts\n",
      "{ CKPT_EPOCH        }->13\n",
      "{ CKPT_PATH         }->None\n",
      "{ CKPT_VERSION      }->ban_8\n",
      "{ CLASSIFER_DROPOUT_R }->0.5\n",
      "{ DATASET           }->vqa\n",
      "{ DATA_PATH         }->{'vqa': './data/vqa', 'gqa': './data/gqa', 'clevr': './data/clevr'}\n",
      "{ DATA_ROOT         }->./data\n",
      "{ DEVICES           }->[0]\n",
      "{ DROPOUT_R         }->0.2\n",
      "{ EVAL_BATCH_SIZE   }->32\n",
      "{ EVAL_EVERY_EPOCH  }->False\n",
      "{ FEATS_PATH        }->{'vqa': {'train': './data/vqa/feats/train2014', 'val': './data/vqa/feats/val2014', 'test': './data/vqa/feats/test2015'}, 'gqa': {'default-frcn': './data/gqa/feats/gqa-frcn', 'default-grid': './data/gqa/feats/gqa-grid'}, 'clevr': {'train': './data/clevr/feats/train', 'val': './data/clevr/feats/val', 'test': './data/clevr/feats/test'}}\n",
      "{ FEAT_SIZE         }->{'vqa': {'FRCN_FEAT_SIZE': (100, 2048), 'BBOX_FEAT_SIZE': (100, 5)}, 'gqa': {'FRCN_FEAT_SIZE': (100, 2048), 'GRID_FEAT_SIZE': (49, 2048), 'BBOX_FEAT_SIZE': (100, 5)}, 'clevr': {'GRID_FEAT_SIZE': (196, 1024)}}\n",
      "{ FLAT_OUT_SIZE     }->2048\n",
      "{ GLIMPSE           }->8\n",
      "{ GPU               }->0\n",
      "{ GRAD_ACCU_STEPS   }->8\n",
      "{ GRAD_NORM_CLIP    }->0.25\n",
      "{ HIDDEN_SIZE       }->1024\n",
      "{ IMG_FEAT_SIZE     }->2048\n",
      "{ K_TIMES           }->3\n",
      "{ LOG_PATH          }->./results/log\n",
      "{ LOSS_FUNC         }->bce\n",
      "{ LOSS_FUNC_NAME_DICT }->{'ce': 'CrossEntropyLoss', 'bce': 'BCEWithLogitsLoss', 'kld': 'KLDivLoss', 'mse': 'MSELoss'}\n",
      "{ LOSS_FUNC_NONLINEAR }->{'ce': [None, 'flat'], 'bce': [None, None], 'kld': ['log_softmax', None], 'mse': [None, None]}\n",
      "{ LOSS_REDUCTION    }->sum\n",
      "{ LR_BASE           }->0.002\n",
      "{ LR_DECAY_LIST     }->[10, 12]\n",
      "{ LR_DECAY_R        }->0.25\n",
      "{ MAX_EPOCH         }->13\n",
      "{ MODEL             }->ban_8\n",
      "{ MODEL_USE         }->ban\n",
      "{ NUM_WORKERS       }->2\n",
      "{ N_GPU             }->1\n",
      "{ OPT               }->Adamax\n",
      "{ OPT_PARAMS        }->{'betas': (0.9, 0.999), 'eps': 1e-09, 'weight_decay': 0}\n",
      "{ PIN_MEM           }->True\n",
      "{ PRED_PATH         }->./results/pred\n",
      "{ RAW_PATH          }->{'vqa': {'train': './data/vqa/raw/v2_OpenEnded_mscoco_train2014_questions.json', 'train-anno': './data/vqa/raw/v2_mscoco_train2014_annotations.json', 'val': './data/vqa/raw/v2_OpenEnded_mscoco_val2014_questions.json', 'val-anno': './data/vqa/raw/v2_mscoco_val2014_annotations.json', 'vg': './data/vqa/raw/VG_questions.json', 'vg-anno': './data/vqa/raw/VG_annotations.json', 'test': './data/vqa/raw/v2_OpenEnded_mscoco_test2015_questions.json'}, 'gqa': {'train': './data/gqa/raw/questions1.2/train_balanced_questions.json', 'val': './data/gqa/raw/questions1.2/val_balanced_questions.json', 'testdev': './data/gqa/raw/questions1.2/testdev_balanced_questions.json', 'test': './data/gqa/raw/questions1.2/submission_all_questions.json', 'val_all': './data/gqa/raw/questions1.2/val_all_questions.json', 'testdev_all': './data/gqa/raw/questions1.2/testdev_all_questions.json', 'train_choices': './data/gqa/raw/eval/train_choices', 'val_choices': './data/gqa/raw/eval/val_choices.json'}, 'clevr': {'train': './data/clevr/raw/questions/CLEVR_train_questions.json', 'val': './data/clevr/raw/questions/CLEVR_val_questions.json', 'test': './data/clevr/raw/questions/CLEVR_test_questions.json'}}\n",
      "{ RESULT_PATH       }->./results/result_test\n",
      "{ RESUME            }->False\n",
      "{ RUN_MODE          }->val\n",
      "{ SEED              }->2666747\n",
      "{ SPLIT             }->{'train': 'train', 'val': 'val', 'test': 'test'}\n",
      "{ SPLITS            }->{'vqa': {'train': 'train', 'val': 'val', 'test': 'test'}, 'gqa': {'train': '', 'val': 'testdev', 'test': 'test'}, 'clevr': {'train': '', 'val': 'val', 'test': 'test'}}\n",
      "{ SUB_BATCH_SIZE    }->64\n",
      "{ TASK_LOSS_CHECK   }->{'vqa': ['bce', 'kld'], 'gqa': ['ce'], 'clevr': ['ce']}\n",
      "{ TEST_SAVE_PRED    }->False\n",
      "{ TRAIN_SPLIT       }->train\n",
      "{ USE_GLOVE         }->True\n",
      "{ VERBOSE           }->True\n",
      "{ VERSION           }->2666747\n",
      "{ WARMUP_EPOCH      }->3\n",
      "{ WORD_EMBED_SIZE   }->300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import yaml\n",
    "from yaml import CLoader\n",
    "\n",
    "from openvqa.models.model_loader import CfgLoader\n",
    "from run import create_parser\n",
    "from utils.test_engine import test_engine\n",
    "\n",
    "parser = create_parser()\n",
    "arg = '--RUN val --MODEL ban_8 --DATASET vqa --NW 2 --CKPT_V ban_8 --CKPT_E 13'\n",
    "args = parser.parse_args(arg.split(' '))\n",
    "\n",
    "cfg_file = \"configs/{}/{}.yml\".format(args.DATASET, args.MODEL)\n",
    "with open(cfg_file, 'r') as f:\n",
    "    yaml_dict = yaml.load(f, Loader=CLoader)\n",
    "\n",
    "__C = CfgLoader(yaml_dict['MODEL_USE']).load()\n",
    "args = __C.str_to_bool(args)\n",
    "args_dict = __C.parse_to_dict(args)\n",
    "\n",
    "args_dict = {**yaml_dict, **args_dict}\n",
    "__C.add_args(args_dict)\n",
    "__C.proc()\n",
    "\n",
    "print('Hyper Parameters:')\n",
    "print(__C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "czhtig1Y8zZO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== Dataset size: 214354\n",
      " ========== Question token vocab size: 20573\n",
      " ========== Answer token vocab size (occur more than 8 times): 3129\n",
      "Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openvqa.datasets.dataset_loader import DatasetLoader, EvalLoader\n",
    "\n",
    "dataset = DatasetLoader(__C).DataSet()\n",
    "\n",
    "data_size = dataset.data_size\n",
    "token_size = dataset.token_size\n",
    "ans_size = dataset.ans_size\n",
    "pretrained_emb = dataset.pretrained_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8s56dZbZK_MJ"
   },
   "outputs": [],
   "source": [
    "from openvqa.models.model_loader import ModelLoader\n",
    "\n",
    "net = ModelLoader(__C).Net(\n",
    "    __C,\n",
    "    pretrained_emb,\n",
    "    token_size,\n",
    "    ans_size\n",
    ")\n",
    "\n",
    "# net.cuda()\n",
    "net.eval()\n",
    "\n",
    "with open('ckpts/ckpt_ban_8/epoch13.pkl', 'rb') as f:\n",
    "    state = torch.load(f, map_location=torch.device('cpu'))\n",
    "net.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Agvd5qHvWSo1"
   },
   "outputs": [],
   "source": [
    "dataloader = Data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=__C.EVAL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=__C.NUM_WORKERS,\n",
    "    pin_memory=__C.PIN_MEM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "WpoSdOZgaMr_",
    "outputId": "5418d092-f59f-4591-f6ae-c5edae17bc83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [step   11/13993]          CPU times: user 1min 12s, sys: 4.35 s, total: 1min 16s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans_ix_list = []\n",
    "pred_list = []\n",
    "\n",
    "for step, (\n",
    "        frcn_feat_iter,\n",
    "        grid_feat_iter,\n",
    "        bbox_feat_iter,\n",
    "        ques_ix_iter,\n",
    "        ans_iter\n",
    "    ) in enumerate(dataloader):\n",
    "    print(\"\\rEvaluation: [step %4d/%4d]\" % (\n",
    "        step,\n",
    "        int(data_size / __C.EVAL_BATCH_SIZE),\n",
    "    ), end='          ')\n",
    "    pred = net(\n",
    "        frcn_feat_iter,\n",
    "        grid_feat_iter,\n",
    "        bbox_feat_iter,\n",
    "        ques_ix_iter\n",
    "    )\n",
    "    pred_np = pred.data.numpy()\n",
    "    pred_argmax = np.argmax(pred_np, axis=1)\n",
    "    \n",
    "    if pred_argmax.shape[0] != __C.EVAL_BATCH_SIZE:\n",
    "        pred_argmax = np.pad(\n",
    "            pred_argmax,\n",
    "            (0, __C.EVAL_BATCH_SIZE - pred_argmax.shape[0]),\n",
    "            mode='constant',\n",
    "            constant_values=-1\n",
    "        )\n",
    "\n",
    "    ans_ix_list.append(pred_argmax)\n",
    "    \n",
    "    if __C.TEST_SAVE_PRED:\n",
    "        if pred_np.shape[0] != __C.EVAL_BATCH_SIZE:\n",
    "            pred_np = np.pad(\n",
    "                pred_np,\n",
    "                ((0, __C.EVAL_BATCH_SIZE - pred_np.shape[0]), (0, 0)),\n",
    "                mode='constant',\n",
    "                constant_values=-1\n",
    "            )\n",
    "\n",
    "        pred_list.append(pred_np)\n",
    "    if step > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   9,   66,    9,    3,    3, 2472,  232,    4,  785,  233,    9,\n",
       "          9,    3,    3,    9,    3, 1273,  288,    9, 1535,  318,   30,\n",
       "        758,  725,    9,    9,    9,   32,   12,    9,    9, 2518,   59,\n",
       "          3,    9,    4, 1075,    9,   17,  593,    9,  448,  418,  286,\n",
       "         13, 1303,    3,    9,    3, 1011,  438,   10,    3,    4,    3,\n",
       "         40,    4,   17,    9,    9,    9,    3,    9,    4,  168,   59,\n",
       "          3,  257,    3,  645,  645,  257,  237,  257,  208,  371,  371,\n",
       "        395,    3,    9,   65,    3,  672,   82,  232,  296,    9,  821,\n",
       "         83,   74, 1096,    9,    3,    9,  514,   16,  268,   30,    9,\n",
       "        891,   60,    9,    9, 1009, 2306,    9,    9,    9,  392, 1680,\n",
       "          3, 1468,   75,    3, 1016,   30,    9,    9,    3,   17,    3,\n",
       "        829,  295, 1186,  672,  120,  221,    9,    3,    3,    6,    3,\n",
       "          9,    9,    9,  232,  268,    9,   30,    3,    9,    3,    9,\n",
       "        252, 1938,  176,    3,  655,   53,    9,    9,    9,    9,    3,\n",
       "         17,    9,  339,  655,   11,    9,    9,  178,    3,  988,   82,\n",
       "          9,    9,  334,   81,  350,    3,  686,   30,    3,    3,  930,\n",
       "        686,    9,    9,    9,    9,  837,    3,   60,    6,    9,  257,\n",
       "         96,    6,  644,    3,    3,    3, 1025,    3,    3, 1025,  524,\n",
       "          6,    9,    3,    9,   32,    9,    9,    3,  441,  431,    9,\n",
       "          3, 2444,    9,    3,   40,   40,   17,  972,   17,  239,   42,\n",
       "          9,   40,  353,    3,    3,    3, 1317,  628,    3,    9,    9,\n",
       "          9,    9,    3,    4,  484,   91,  267,    9,    3,    9,  304,\n",
       "        304, 1381,    2,    3,    3,    9,  475,  139,    3,  838,  886,\n",
       "          3,    3,    3,   12,   12,  134,  395,   12,    3,   83,   91,\n",
       "         83,    9,    9,  395,    9,  762,   17,    9,    3,   21,    3,\n",
       "          9,    4,  212, 1025,    4,   12,    9,  134,    9,    3,   21,\n",
       "         21,    3,    3, 1079,  809,    9,   11,  725,  431,  395,    9,\n",
       "          9,    9,    9,  214,   12,    3,    9,    9,  233,  252,  176,\n",
       "          3,   36,    3,   14,  176,    9,   59,  930,  250,    3,   17,\n",
       "          3,   17,    3,    9,   12,    3,    9,    9,   32,    3, 1207,\n",
       "          9, 1733,    9,    9,    9,    9,  201,  120,  120,  280,    9,\n",
       "         27,   13,    3, 2778,  198,    3, 1293,  749,  676,    3,   49,\n",
       "          3,   48,  120,    9,    3,    3,    9,    9,   30,   13,   45,\n",
       "        120,  221,    9,    3,  100,   30,    3,    9,  288,    3,  240,\n",
       "       1064,    3,   32,    3,   13,  231,    9,   30,    9,  339])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_ix_list = np.array(ans_ix_list).reshape(-1)\n",
    "ans_ix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_list = [ques['question_id'] for ques in dataset.ques_list]\n",
    "ans_size = dataset.ans_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [{\n",
    "        'answer': dataset.ix_to_ans[str(ans_ix_list[qix])],\n",
    "        'question_id': int(qid_list[qix])\n",
    "    } for qix in range(ans_ix_list.__len__())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the result to file: ./results/cache/result_run_2666747\n"
     ]
    }
   ],
   "source": [
    "result_eval_file = __C.CACHE_PATH + '/result_run_' + __C.VERSION\n",
    "log_file = __C.LOG_PATH + '/log_run_' + __C.VERSION + '.txt'\n",
    "\n",
    "print('Save the result to file: {}'.format(result_eval_file))\n",
    "with open(result_eval_file, 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:07.463692\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from openvqa.datasets.vqa.eval.vqa import VQA\n",
    "\n",
    "ques_file_path = __C.RAW_PATH[__C.DATASET][__C.SPLIT['val']]\n",
    "ans_file_path = __C.RAW_PATH[__C.DATASET][__C.SPLIT['val'] + '-anno']\n",
    "# uncomment line 165-166 in http://localhost:8888/edit/openvqa/openvqa/datasets/vqa/eval/vqa.py\n",
    "vqa = VQA(ans_file_path, ques_file_path)\n",
    "vqaRes = vqa.loadRes(result_eval_file, ques_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvqa.datasets.vqa.eval.vqaEval import VQAEval\n",
    "vqaEval = VQAEval(vqa, vqaRes, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "quesIds = [d['question_id'] for d in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing accuracy\n",
      "Finished Percent: [################----] 78% Done computing accuracy\n"
     ]
    }
   ],
   "source": [
    "vqaEval.evaluate(quesIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 10.36,\n",
       " 'perQuestionType': {'none of the above': 28.57,\n",
       "  'what are the': 0.0,\n",
       "  'what is': 0.0,\n",
       "  'what': 0.0,\n",
       "  'is this a': 7.69,\n",
       "  'is this': 15.71,\n",
       "  'what is the man': 0.0,\n",
       "  'how many': 0.0,\n",
       "  'what does the': 0.0,\n",
       "  'why': 3.75,\n",
       "  'is it': 16.25,\n",
       "  'why is the': 0.0,\n",
       "  'what color is the': 0.0,\n",
       "  'is there a': 11.11,\n",
       "  'is the': 27.19,\n",
       "  'is that a': 50.0,\n",
       "  'are these': 0.0,\n",
       "  'are the': 36.0,\n",
       "  'what is the': 0.0,\n",
       "  'which': 0.0,\n",
       "  'could': 0.0,\n",
       "  'are there': 20.0,\n",
       "  'what kind of': 0.0,\n",
       "  'has': 0.0,\n",
       "  'what color are the': 0.0,\n",
       "  'are there any': 50.0,\n",
       "  'is this person': 63.33,\n",
       "  'does the': 12.5,\n",
       "  'where is the': 0.0,\n",
       "  'how many people are': 0.0,\n",
       "  'can you': 0.0,\n",
       "  'what type of': 0.0,\n",
       "  'what is the color of the': 0.0,\n",
       "  'what is on the': 0.0,\n",
       "  'does this': 72.5,\n",
       "  'is this an': 66.67,\n",
       "  'who is': 0.0,\n",
       "  'what is this': 0.0,\n",
       "  'is there': 43.33,\n",
       "  'are': 33.33,\n",
       "  'what time': 0.0,\n",
       "  'how': 0.0,\n",
       "  'what is in the': 0.0,\n",
       "  'do you': 0.0,\n",
       "  'what are': 0.0,\n",
       "  'what sport is': 0.0,\n",
       "  'what is the person': 0.0,\n",
       "  'is he': 30.0,\n",
       "  'where are the': 0.0,\n",
       "  'what brand': 0.0,\n",
       "  'what number is': 0.0,\n",
       "  'what color is': 0.0,\n",
       "  'what is the woman': 0.0,\n",
       "  'what room is': 0.0,\n",
       "  'is': 50.0,\n",
       "  'what color': 0.0,\n",
       "  'is the woman': 0.0,\n",
       "  'are they': 0.0,\n",
       "  'is the person': 0.0,\n",
       "  'is the man': 0.0,\n",
       "  'what animal is': 0.0,\n",
       "  'what is the name': 0.0,\n",
       "  'was': 0.0},\n",
       " 'perAnswerType': {'other': 0.15, 'yes/no': 27.62, 'number': 0.0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqaEval.accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "openvqa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
