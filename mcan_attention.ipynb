{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDHHBqnjRij2"
   },
   "source": [
    "## Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFBMHegVYwgx"
   },
   "source": [
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/openvqa/core/base_cfgs.py\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/utils/exec.py#L36\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/utils/test_engine.py#L49\n",
    "https://github.com/MILVLG/openvqa/blob/6b9bfeb2e6462b946d7e7866ffc49dd7a8bcece3/openvqa/datasets/vqa/vqa_loader.py#L68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyONyychRXaF"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08lNunGuD52d",
    "outputId": "f7a39a95-7e65-477d-97d8-8048a7b50c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset ........\n",
      "Finished!\n",
      "\n",
      "Hyper Parameters:\n",
      "{ BATCH_SIZE        }->64\n",
      "{ BBOXFEAT_EMB_SIZE }->2048\n",
      "{ BBOX_NORMALIZE    }->True\n",
      "{ CACHE_PATH        }->./results/cache\n",
      "{ CKPTS_PATH        }->./ckpts\n",
      "{ CKPT_EPOCH        }->13\n",
      "{ CKPT_PATH         }->None\n",
      "{ CKPT_VERSION      }->mcan_large\n",
      "{ DATASET           }->vqa\n",
      "{ DATA_PATH         }->{'vqa': './data/vqa', 'gqa': './data/gqa', 'clevr': './data/clevr'}\n",
      "{ DATA_ROOT         }->./data\n",
      "{ DEVICES           }->[0]\n",
      "{ DROPOUT_R         }->0.1\n",
      "{ EVAL_BATCH_SIZE   }->16\n",
      "{ EVAL_EVERY_EPOCH  }->False\n",
      "{ FEATS_PATH        }->{'vqa': {'train': './data/vqa/feats/train2014', 'val': './data/vqa/feats/val2014', 'test': './data/vqa/feats/test2015'}, 'gqa': {'default-frcn': './data/gqa/feats/gqa-frcn', 'default-grid': './data/gqa/feats/gqa-grid'}, 'clevr': {'train': './data/clevr/feats/train', 'val': './data/clevr/feats/val', 'test': './data/clevr/feats/test'}}\n",
      "{ FEAT_SIZE         }->{'vqa': {'FRCN_FEAT_SIZE': (100, 2048), 'BBOX_FEAT_SIZE': (100, 5)}, 'gqa': {'FRCN_FEAT_SIZE': (100, 2048), 'GRID_FEAT_SIZE': (49, 2048), 'BBOX_FEAT_SIZE': (100, 5)}, 'clevr': {'GRID_FEAT_SIZE': (196, 1024)}}\n",
      "{ FF_SIZE           }->4096\n",
      "{ FLAT_GLIMPSES     }->1\n",
      "{ FLAT_MLP_SIZE     }->512\n",
      "{ FLAT_OUT_SIZE     }->2048\n",
      "{ GPU               }->0\n",
      "{ GRAD_ACCU_STEPS   }->2\n",
      "{ GRAD_NORM_CLIP    }->-1\n",
      "{ HIDDEN_SIZE       }->1024\n",
      "{ LAYER             }->6\n",
      "{ LOG_PATH          }->./results/log\n",
      "{ LOSS_FUNC         }->bce\n",
      "{ LOSS_FUNC_NAME_DICT }->{'ce': 'CrossEntropyLoss', 'bce': 'BCEWithLogitsLoss', 'kld': 'KLDivLoss', 'mse': 'MSELoss'}\n",
      "{ LOSS_FUNC_NONLINEAR }->{'ce': [None, 'flat'], 'bce': [None, None], 'kld': ['log_softmax', None], 'mse': [None, None]}\n",
      "{ LOSS_REDUCTION    }->sum\n",
      "{ LR_BASE           }->7e-05\n",
      "{ LR_DECAY_LIST     }->[10, 12]\n",
      "{ LR_DECAY_R        }->0.2\n",
      "{ MAX_EPOCH         }->13\n",
      "{ MODEL             }->mcan_large\n",
      "{ MODEL_USE         }->mcan\n",
      "{ MULTI_HEAD        }->8\n",
      "{ NUM_WORKERS       }->2\n",
      "{ N_GPU             }->1\n",
      "{ OPT               }->Adam\n",
      "{ OPT_PARAMS        }->{'betas': (0.9, 0.98), 'eps': 1e-09, 'weight_decay': 0, 'amsgrad': False}\n",
      "{ PIN_MEM           }->True\n",
      "{ PRED_PATH         }->./results/pred\n",
      "{ RAW_PATH          }->{'vqa': {'train': './data/vqa/raw/v2_OpenEnded_mscoco_train2014_questions.json', 'train-anno': './data/vqa/raw/v2_mscoco_train2014_annotations.json', 'val': './data/vqa/raw/v2_OpenEnded_mscoco_val2014_questions.json', 'val-anno': './data/vqa/raw/v2_mscoco_val2014_annotations.json', 'vg': './data/vqa/raw/VG_questions.json', 'vg-anno': './data/vqa/raw/VG_annotations.json', 'test': './data/vqa/raw/v2_OpenEnded_mscoco_test2015_questions.json'}, 'gqa': {'train': './data/gqa/raw/questions1.2/train_balanced_questions.json', 'val': './data/gqa/raw/questions1.2/val_balanced_questions.json', 'testdev': './data/gqa/raw/questions1.2/testdev_balanced_questions.json', 'test': './data/gqa/raw/questions1.2/submission_all_questions.json', 'val_all': './data/gqa/raw/questions1.2/val_all_questions.json', 'testdev_all': './data/gqa/raw/questions1.2/testdev_all_questions.json', 'train_choices': './data/gqa/raw/eval/train_choices', 'val_choices': './data/gqa/raw/eval/val_choices.json'}, 'clevr': {'train': './data/clevr/raw/questions/CLEVR_train_questions.json', 'val': './data/clevr/raw/questions/CLEVR_val_questions.json', 'test': './data/clevr/raw/questions/CLEVR_test_questions.json'}}\n",
      "{ RESULT_PATH       }->./results/result_test\n",
      "{ RESUME            }->False\n",
      "{ RUN_MODE          }->test\n",
      "{ SEED              }->8398387\n",
      "{ SPLIT             }->{'train': 'train', 'val': 'val', 'test': 'test'}\n",
      "{ SPLITS            }->{'vqa': {'train': 'train', 'val': 'val', 'test': 'test'}, 'gqa': {'train': '', 'val': 'testdev', 'test': 'test'}, 'clevr': {'train': '', 'val': 'val', 'test': 'test'}}\n",
      "{ SUB_BATCH_SIZE    }->32\n",
      "{ TASK_LOSS_CHECK   }->{'vqa': ['bce', 'kld'], 'gqa': ['ce'], 'clevr': ['ce']}\n",
      "{ TEST_SAVE_PRED    }->False\n",
      "{ TRAIN_SPLIT       }->train\n",
      "{ USE_AUX_FEAT      }->False\n",
      "{ USE_BBOX_FEAT     }->False\n",
      "{ USE_GLOVE         }->True\n",
      "{ VERBOSE           }->True\n",
      "{ VERSION           }->8398387\n",
      "{ WARMUP_EPOCH      }->3\n",
      "{ WORD_EMBED_SIZE   }->300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import yaml\n",
    "from yaml import CLoader\n",
    "\n",
    "from openvqa.datasets.dataset_loader import DatasetLoader, EvalLoader\n",
    "from openvqa.datasets.vqa.eval.vqa import VQA\n",
    "from openvqa.datasets.vqa.eval.vqaEval import VQAEval\n",
    "from openvqa.models.model_loader import CfgLoader, ModelLoader\n",
    "from run import create_parser\n",
    "from utils.test_engine import test_engine\n",
    "\n",
    "parser = create_parser()\n",
    "arg = '--RUN test --MODEL mcan_large --DATASET vqa --NW 2 --CKPT_V mcan_large --CKPT_E 13'\n",
    "args = parser.parse_args(arg.split(' '))\n",
    "\n",
    "cfg_file = \"configs/{}/{}.yml\".format(args.DATASET, args.MODEL)\n",
    "with open(cfg_file, 'r') as f:\n",
    "    yaml_dict = yaml.load(f, Loader=CLoader)\n",
    "\n",
    "__C = CfgLoader(yaml_dict['MODEL_USE']).load()\n",
    "args = __C.str_to_bool(args)\n",
    "args_dict = __C.parse_to_dict(args)\n",
    "\n",
    "args_dict = {**yaml_dict, **args_dict}\n",
    "__C.add_args(args_dict)\n",
    "__C.proc()\n",
    "\n",
    "print('Hyper Parameters:')\n",
    "print(__C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czhtig1Y8zZO",
    "outputId": "7e96770a-4c0a-4e32-f467-6f12a9bc6321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========== Dataset size: 447793\n",
      " ========== Question token vocab size: 20573\n",
      " ========== Answer token vocab size (occur more than 8 times): 3129\n",
      "Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetLoader(__C).DataSet()\n",
    "\n",
    "data_size = dataset.data_size\n",
    "token_size = dataset.token_size\n",
    "ans_size = dataset.ans_size\n",
    "pretrained_emb = dataset.pretrained_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s56dZbZK_MJ",
    "outputId": "037027f0-ad9d-4a90-fd0d-26c0ed16535a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ModelLoader(__C).Net(\n",
    "    __C,\n",
    "    pretrained_emb,\n",
    "    token_size,\n",
    "    ans_size\n",
    ")\n",
    "\n",
    "net.cuda()\n",
    "net.eval()\n",
    "\n",
    "with open('ckpts/ckpt_mcan_large/epoch13.pkl', 'rb') as f:\n",
    "    state = torch.load(f, map_location='cpu')\n",
    "net.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Agvd5qHvWSo1"
   },
   "outputs": [],
   "source": [
    "dataloader = Data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=__C.EVAL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=__C.NUM_WORKERS,\n",
    "    pin_memory=__C.PIN_MEM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvqa.utils.make_mask import make_mask\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_mcan_att(v, k, q, mask, net_module):\n",
    "    \"\"\"Forward MHAtt module to get the attention map (intermediate values).\n",
    "    Default softmax is over text tokens (using text mask)\n",
    "    We twist it over visual regions for visualization (using visual mask).\n",
    "    \"\"\"\n",
    "    n_batches = q.size(0)\n",
    "\n",
    "    v = net_module.linear_v(v).view(\n",
    "        n_batches,\n",
    "        -1,\n",
    "        net_module._MHAtt__C.MULTI_HEAD,\n",
    "        int(net_module._MHAtt__C.HIDDEN_SIZE / net_module._MHAtt__C.MULTI_HEAD)\n",
    "    ).transpose(1, 2)\n",
    "\n",
    "    k = net_module.linear_k(k).view(\n",
    "        n_batches,\n",
    "        -1,\n",
    "        net_module._MHAtt__C.MULTI_HEAD,\n",
    "        int(net_module._MHAtt__C.HIDDEN_SIZE / net_module._MHAtt__C.MULTI_HEAD)\n",
    "    ).transpose(1, 2)\n",
    "\n",
    "    q = net_module.linear_q(q).view(\n",
    "        n_batches,\n",
    "        -1,\n",
    "        net_module._MHAtt__C.MULTI_HEAD,\n",
    "        int(net_module._MHAtt__C.HIDDEN_SIZE / net_module._MHAtt__C.MULTI_HEAD)\n",
    "    ).transpose(1, 2)\n",
    "    \n",
    "    # att computation\n",
    "    d_k = q.size(-1)\n",
    "\n",
    "    scores = torch.matmul(\n",
    "        q, k.transpose(-2, -1)\n",
    "    ) / math.sqrt(d_k)\n",
    "    \n",
    "    # softmax over visual regions for visualization\n",
    "    scores = scores.transpose(-1, -2)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    scores = scores.transpose(-1, -2)\n",
    "    att_map = F.softmax(scores, dim=-2)\n",
    "    \n",
    "    # default softmax over text tokens\n",
    "    # if mask is not None:\n",
    "        # scores = scores.masked_fill(mask, -1e9)\n",
    "    # att_map = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    return att_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: [step 27987/27987]          (447793, 100)\n",
      "CPU times: user 22min 34s, sys: 5min 49s, total: 28min 24s\n",
      "Wall time: 24min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atts = []\n",
    "i = 0\n",
    "for step, (frcn_feat, grid_feat, bbox_feat, ques_ix, ans) in enumerate(dataloader):\n",
    "    print(\"\\rEvaluation: [step %4d/%4d]\" % (\n",
    "        step,\n",
    "        int(data_size / __C.EVAL_BATCH_SIZE),\n",
    "    ), end='          ')\n",
    "    \n",
    "    frcn_feat = frcn_feat.cuda()\n",
    "    grid_feat = grid_feat.cuda()\n",
    "    bbox_feat = bbox_feat.cuda()\n",
    "    ques_ix = ques_ix.cuda()\n",
    "    \n",
    "    lang_feat_mask = make_mask(ques_ix.unsqueeze(2))\n",
    "    lang_feat = net.embedding(ques_ix)\n",
    "    lang_feat, _ = net.lstm(lang_feat)\n",
    "\n",
    "    img_feat, img_feat_mask  = net.adapter(frcn_feat, grid_feat, bbox_feat)\n",
    "    #print('img_feat.shape:\\t', img_feat.shape)\n",
    "    #print('lang_feat.shape:\\t', lang_feat.shape)\n",
    "    \n",
    "    y = lang_feat\n",
    "    x = img_feat\n",
    "    y_mask = lang_feat_mask\n",
    "    x_mask = img_feat_mask\n",
    "    \n",
    "    # Get encoder last hidden vector\n",
    "    for enc in net.backbone.enc_list:\n",
    "        y = enc(y, y_mask)\n",
    "    \n",
    "    # Input encoder last hidden vector, and obtain decoder last hidden vectors\n",
    "    for dec_i, dec in enumerate(net.backbone.dec_list):\n",
    "        if dec_i != len(net.backbone.dec_list) - 1: # intermediate layers\n",
    "            x = dec.norm1(x + dec.dropout1(dec.mhatt1(v=x, k=x, q=x, mask=x_mask)))\n",
    "            x = dec.norm2(x + dec.dropout2(dec.mhatt2(v=y, k=y, q=x, mask=y_mask)))\n",
    "            x = dec.norm3(x + dec.dropout3(dec.ffn(x)))\n",
    "        else: # last layer\n",
    "            x = dec.norm1(x + dec.dropout1(dec.mhatt1(v=x, k=x, q=x, mask=x_mask)))\n",
    "            att = get_mcan_att(v=y, k=y, q=x, mask=x_mask, net_module=dec.mhatt2)\n",
    "            #print('att_map.shape:\\t', att_map.shape)\n",
    "\n",
    "    atts.append(att.detach().cpu().numpy().sum(axis=-1).mean(axis=1))\n",
    "#     i += 1\n",
    "#     if i > 3:\n",
    "#         break\n",
    "res = np.concatenate(atts)\n",
    "print(res.shape)\n",
    "np.savez_compressed('att_weight_mcan', att=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447793, 100)\n"
     ]
    }
   ],
   "source": [
    "res = np.concatenate(atts)\n",
    "print(res.shape)\n",
    "np.savez_compressed('att_weight_mcan', att=res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "openvqa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "openvqa",
   "language": "python",
   "name": "openvqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
